{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the optimal number of hidden layers and neurons for an Artificial Neural Network (ANN) \n",
    "This can be challenging and often requires experimentation. However, there are some guidelines and methods that can help you in making an informed decision:\n",
    "\n",
    "- Start Simple: Begin with a simple architecture and gradually increase complexity if needed.\n",
    "- Grid Search/Random Search: Use grid search or random search to try different architectures.\n",
    "- Cross-Validation: Use cross-validation to evaluate the performance of different architectures.\n",
    "- Heuristics and Rules of Thumb: Some heuristics and empirical rules can provide starting points, such as:\n",
    "  -    The number of neurons in the hidden layer should be between the size of the input layer and the size of the output layer.\n",
    "  -  A common practice is to start with 1-2 hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T12:53:47.898690Z",
     "start_time": "2025-06-28T12:53:34.492018Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pickle"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T12:53:47.951926Z",
     "start_time": "2025-06-28T12:53:47.899695Z"
    }
   },
   "source": [
    "data=pd.read_csv('Churn_Modelling.csv')\n",
    "data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "label_encoder_gender = LabelEncoder()\n",
    "data['Gender'] = label_encoder_gender.fit_transform(data['Gender'])\n",
    "\n",
    "onehot_encoder_geo = OneHotEncoder(handle_unknown='ignore')\n",
    "geo_encoded = onehot_encoder_geo.fit_transform(data[['Geography']]).toarray()\n",
    "geo_encoded_df = pd.DataFrame(geo_encoded, columns=onehot_encoder_geo.get_feature_names_out(['Geography']))\n",
    "\n",
    "\n",
    "data = pd.concat([data.drop('Geography', axis=1), geo_encoded_df], axis=1)\n",
    "\n",
    "X = data.drop('Exited', axis=1)\n",
    "y = data['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Save encoders and scaler for later use\n",
    "with open('label_encoder_gender.pkl', 'wb') as file:\n",
    "    pickle.dump(label_encoder_gender, file)\n",
    "\n",
    "with open('onehot_encoder_geo.pkl', 'wb') as file:\n",
    "    pickle.dump(onehot_encoder_geo, file)\n",
    "\n",
    "with open('scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)\n",
    "    \n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def model_builder(hp):\n",
    "    model = Sequential()\n",
    "    hp_neurons = hp.Choice('units', values=[16, 32, 64, 128])\n",
    "    hp_layers = hp.Int('layers', 1, 3)\n",
    "    \n",
    "    model.add(Dense(hp_neurons, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    for _ in range(hp_layers - 1):\n",
    "        model.add(Dense(hp_neurons, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = kt.RandomSearch(model_builder,\n",
    "                        objective='val_accuracy',\n",
    "                        max_trials=10,\n",
    "                        executions_per_trial=1,\n",
    "                        directory='my_dir',\n",
    "                        project_name='keras_tuning')\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 19s]\n",
      "val_accuracy: 0.859375\n",
      "\n",
      "Best val_accuracy So Far: 0.8631250262260437\n",
      "Total elapsed time: 00h 02m 57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\GenAI_langchain_project\\venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 10 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
